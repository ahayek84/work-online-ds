{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Melbourne_housing_FULL..ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5afMEslyVHX",
        "colab_type": "code",
        "outputId": "89f7acbb-8c6e-462b-d1e1-3394c74e2c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzmmDmW-uv12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSOFMlk4u7W5",
        "colab_type": "code",
        "outputId": "50409ee7-f813-4d90-c2cf-c15abd5e7055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "url = \"https://github.com/motazsaad/work-online-ds/raw/master/data/melbourne-housing-market/Melbourne_housing_FULL.csv\"\n",
        "\n",
        "dataframe = pd.read_csv(url)\n",
        "dataframe.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Suburb</th>\n",
              "      <th>Address</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Method</th>\n",
              "      <th>SellerG</th>\n",
              "      <th>Date</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>68 Studley St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SS</td>\n",
              "      <td>Jellis</td>\n",
              "      <td>3/09/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra City Council</td>\n",
              "      <td>-37.8014</td>\n",
              "      <td>144.9958</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>85 Turner St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1480000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>3/12/2016</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yarra City Council</td>\n",
              "      <td>-37.7996</td>\n",
              "      <td>144.9984</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Suburb        Address  ...             Regionname Propertycount\n",
              "0  Abbotsford  68 Studley St  ...  Northern Metropolitan        4019.0\n",
              "1  Abbotsford   85 Turner St  ...  Northern Metropolitan        4019.0\n",
              "\n",
              "[2 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_xC5xyu_Yf",
        "colab_type": "text"
      },
      "source": [
        "# Steps: \n",
        "# 1. execlude obj attributes\n",
        "# 2. split data\n",
        "# 3. load as tensor slice data\n",
        "# 4. shuffle and batch \n",
        "# 5. apply sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXeUjA0Xzlry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = dataframe.select_dtypes(exclude=['object']).dropna(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcbBTsTJw2Ka",
        "colab_type": "code",
        "outputId": "f73da73d-068c-43ad-ad8b-41cf5584191d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train, test = train_test_split(dataframe, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5687 train examples\n",
            "1422 validation examples\n",
            "1778 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSyJyTzbxye3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, target, shuffle=True, batch_size=100):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop(target)\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8XoDF9wyDT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 100 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(dataframe=train, target='Price', shuffle=True, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(dataframe=val,  target='Price', shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(dataframe=test,  target='Price', shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XacSW09b0lhX",
        "colab_type": "code",
        "outputId": "31c1dd49-3b94-4a38-d6f8-3f01d0ef7697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "dataframe.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Rooms', 'Price', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
              "       'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude',\n",
              "       'Propertycount'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rZjPGKX0172",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "# numeric cols\n",
        "for col in dataframe.keys():\n",
        "  if col == 'Price':\n",
        "    continue\n",
        "  feature_columns.append(feature_column.numeric_column(col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QNl6J_Hz5x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.DenseFeatures(feature_columns))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fqhq_xK0COI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model.compile(loss='mse',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4cUuw2z0IZU",
        "colab_type": "code",
        "outputId": "6aa5dba0-8523-4ba1-8089-800cc446b731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=300)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "57/57 [==============================] - 0s 8ms/step - loss: 134704306786.8070 - mae: 245476.9219 - mse: 134714875904.0000 - val_loss: 0.0000e+00 - val_mae: 0.0000e+00 - val_mse: 0.0000e+00\n",
            "Epoch 2/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134647243114.7352 - mae: 244770.0469 - mse: 134414819328.0000 - val_loss: 217934766626.1333 - val_mae: 271459.4062 - val_mse: 205744078848.0000\n",
            "Epoch 3/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133456797470.1861 - mae: 244166.4531 - mse: 133851127808.0000 - val_loss: 216182212198.4000 - val_mae: 263786.5312 - val_mse: 203389829120.0000\n",
            "Epoch 4/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136137862029.5673 - mae: 247092.0781 - mse: 135600447488.0000 - val_loss: 223995327829.3333 - val_mae: 257447.2656 - val_mse: 206341275648.0000\n",
            "Epoch 5/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135743339253.3315 - mae: 247897.4219 - mse: 135971340288.0000 - val_loss: 214853052006.4000 - val_mae: 262644.5000 - val_mse: 201298608128.0000\n",
            "Epoch 6/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134550745888.4131 - mae: 244534.7656 - mse: 134619201536.0000 - val_loss: 222415781341.8667 - val_mae: 257476.1562 - val_mse: 205459849216.0000\n",
            "Epoch 7/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136110051563.7835 - mae: 247267.8281 - mse: 136162549760.0000 - val_loss: 216735999590.4000 - val_mae: 267071.1562 - val_mse: 205376700416.0000\n",
            "Epoch 8/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135689268967.4100 - mae: 245533.0156 - mse: 135062257664.0000 - val_loss: 216250117870.9333 - val_mae: 257925.6094 - val_mse: 201902440448.0000\n",
            "Epoch 9/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134566699590.0290 - mae: 243625.5000 - mse: 133784797184.0000 - val_loss: 215211834299.7333 - val_mae: 259931.3125 - val_mse: 201678602240.0000\n",
            "Epoch 10/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134452724691.7906 - mae: 244496.2031 - mse: 133957255168.0000 - val_loss: 217627066368.0000 - val_mae: 268047.5938 - val_mse: 204878757888.0000\n",
            "Epoch 11/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135035264915.7367 - mae: 244834.6875 - mse: 134105513984.0000 - val_loss: 217101304900.2667 - val_mae: 258903.5781 - val_mse: 201901588480.0000\n",
            "Epoch 12/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135279846818.1462 - mae: 245371.8125 - mse: 134938836992.0000 - val_loss: 217441285461.3333 - val_mae: 265863.4688 - val_mse: 204823445504.0000\n",
            "Epoch 13/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135344597429.0525 - mae: 244361.6719 - mse: 134348472320.0000 - val_loss: 214974662246.4000 - val_mae: 260956.6875 - val_mse: 200931344384.0000\n",
            "Epoch 14/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136833055637.4520 - mae: 246483.7344 - mse: 135926530048.0000 - val_loss: 219247792947.2000 - val_mae: 270893.1562 - val_mse: 204944375808.0000\n",
            "Epoch 15/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135925587622.3610 - mae: 248728.4219 - mse: 136546689024.0000 - val_loss: 221373336234.6667 - val_mae: 257145.3906 - val_mse: 205055803392.0000\n",
            "Epoch 16/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 137081849642.1837 - mae: 246626.8125 - mse: 136925986816.0000 - val_loss: 218082890001.0667 - val_mae: 259642.7500 - val_mse: 203227234304.0000\n",
            "Epoch 17/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134313095494.2683 - mae: 244618.5938 - mse: 133724471296.0000 - val_loss: 216206819874.1333 - val_mae: 259952.6094 - val_mse: 201885532160.0000\n",
            "Epoch 18/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133744712795.6315 - mae: 244327.6875 - mse: 133936914432.0000 - val_loss: 220499762107.7333 - val_mae: 279833.5625 - val_mse: 208958668800.0000\n",
            "Epoch 19/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 135719819308.3705 - mae: 245461.7344 - mse: 134755074048.0000 - val_loss: 218090657655.4667 - val_mae: 271256.5000 - val_mse: 207357476864.0000\n",
            "Epoch 20/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134307678193.7279 - mae: 244569.9844 - mse: 133911781376.0000 - val_loss: 219497021440.0000 - val_mae: 257172.3281 - val_mse: 203634507776.0000\n",
            "Epoch 21/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135485901393.0790 - mae: 244232.9844 - mse: 134567985152.0000 - val_loss: 216870962790.4000 - val_mae: 269619.8750 - val_mse: 204678643712.0000\n",
            "Epoch 22/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133724117242.4347 - mae: 244687.2656 - mse: 134314196992.0000 - val_loss: 218026619699.2000 - val_mae: 268249.8125 - val_mse: 206345355264.0000\n",
            "Epoch 23/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134603592419.6856 - mae: 244315.2656 - mse: 134272278528.0000 - val_loss: 214950846464.0000 - val_mae: 257332.5469 - val_mse: 200984281088.0000\n",
            "Epoch 24/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131846642735.2799 - mae: 244735.2812 - mse: 133580455936.0000 - val_loss: 223321167189.3333 - val_mae: 286741.9062 - val_mse: 212797014016.0000\n",
            "Epoch 25/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 136620813656.0943 - mae: 247889.7031 - mse: 136058912768.0000 - val_loss: 219646692556.8000 - val_mae: 257691.5938 - val_mse: 203888459776.0000\n",
            "Epoch 26/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 135531101724.9091 - mae: 246450.1875 - mse: 134851256320.0000 - val_loss: 215697104349.8667 - val_mae: 260952.4688 - val_mse: 202004545536.0000\n",
            "Epoch 27/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133861146532.7571 - mae: 243580.7969 - mse: 133545754624.0000 - val_loss: 216053436689.0667 - val_mae: 264866.2188 - val_mse: 202992205824.0000\n",
            "Epoch 28/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133731927913.8301 - mae: 244111.7500 - mse: 133954912256.0000 - val_loss: 219321715370.6667 - val_mae: 273606.9688 - val_mse: 207919022080.0000\n",
            "Epoch 29/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133858236461.5836 - mae: 244990.0625 - mse: 133358870528.0000 - val_loss: 215300441702.4000 - val_mae: 261829.3125 - val_mse: 202318200832.0000\n",
            "Epoch 30/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133826301539.4925 - mae: 243712.1094 - mse: 133536866304.0000 - val_loss: 215497365913.6000 - val_mae: 262229.5625 - val_mse: 202413670400.0000\n",
            "Epoch 31/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133924756863.7832 - mae: 243923.3906 - mse: 133307506688.0000 - val_loss: 217578103876.2667 - val_mae: 270841.1250 - val_mse: 205428916224.0000\n",
            "Epoch 32/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134504954771.4050 - mae: 243969.5469 - mse: 133963284480.0000 - val_loss: 219564143957.3333 - val_mae: 256753.5938 - val_mse: 202729717760.0000\n",
            "Epoch 33/300\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 135671875730.1517 - mae: 245256.2188 - mse: 134770909184.0000 - val_loss: 216297223509.3333 - val_mae: 257454.2031 - val_mse: 201523200000.0000\n",
            "Epoch 34/300\n",
            "57/57 [==============================] - 0s 7ms/step - loss: 134888854866.5787 - mae: 245907.4219 - mse: 134772178944.0000 - val_loss: 217842696192.0000 - val_mae: 257819.6094 - val_mse: 202877173760.0000\n",
            "Epoch 35/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132933242876.7400 - mae: 244238.9219 - mse: 134167035904.0000 - val_loss: 215470528375.4667 - val_mae: 262689.3125 - val_mse: 201723346944.0000\n",
            "Epoch 36/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134620972685.4749 - mae: 244413.7656 - mse: 133733769216.0000 - val_loss: 216665736260.2667 - val_mae: 265448.5938 - val_mse: 204584419328.0000\n",
            "Epoch 37/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133487442857.8082 - mae: 243145.4688 - mse: 133142773760.0000 - val_loss: 214566350028.8000 - val_mae: 259908.0469 - val_mse: 201492905984.0000\n",
            "Epoch 38/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133324614295.4350 - mae: 243153.3438 - mse: 133047410688.0000 - val_loss: 215341836424.5333 - val_mae: 259396.7031 - val_mse: 201334308864.0000\n",
            "Epoch 39/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133562060111.0344 - mae: 245120.1562 - mse: 134074392576.0000 - val_loss: 218855860360.5333 - val_mae: 256533.3594 - val_mse: 203531108352.0000\n",
            "Epoch 40/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132315339762.7040 - mae: 243823.5625 - mse: 133231017984.0000 - val_loss: 216531509794.1333 - val_mae: 256974.0000 - val_mse: 201841639424.0000\n",
            "Epoch 41/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133435010868.9305 - mae: 242917.3750 - mse: 133007302656.0000 - val_loss: 215913663692.8000 - val_mae: 259134.8594 - val_mse: 202379689984.0000\n",
            "Epoch 42/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 135138718073.6328 - mae: 246181.8281 - mse: 134303916032.0000 - val_loss: 219592794112.0000 - val_mae: 258564.0938 - val_mse: 204999524352.0000\n",
            "Epoch 43/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136660767348.2760 - mae: 246204.0938 - mse: 135972544512.0000 - val_loss: 218295181312.0000 - val_mae: 257375.5781 - val_mse: 203418419200.0000\n",
            "Epoch 44/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134084079984.8762 - mae: 243174.2344 - mse: 133391196160.0000 - val_loss: 215209763362.1333 - val_mae: 257944.7969 - val_mse: 200349499392.0000\n",
            "Epoch 45/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133333481450.9804 - mae: 243750.8906 - mse: 132998995968.0000 - val_loss: 215854611387.7333 - val_mae: 259120.0000 - val_mse: 201130213376.0000\n",
            "Epoch 46/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133226929744.8421 - mae: 243617.0156 - mse: 133294899200.0000 - val_loss: 214673481728.0000 - val_mae: 259167.5000 - val_mse: 201398304768.0000\n",
            "Epoch 47/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134839345100.9009 - mae: 246353.8438 - mse: 135085826048.0000 - val_loss: 214548330905.6000 - val_mae: 262337.5000 - val_mse: 202162831360.0000\n",
            "Epoch 48/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134408268799.6683 - mae: 245741.5625 - mse: 134794805248.0000 - val_loss: 222689694515.2000 - val_mae: 256470.3750 - val_mse: 205835010048.0000\n",
            "Epoch 49/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135499691312.1589 - mae: 245770.9375 - mse: 135544119296.0000 - val_loss: 216135537459.2000 - val_mae: 267990.1875 - val_mse: 204579913728.0000\n",
            "Epoch 50/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134714159002.6737 - mae: 244033.7656 - mse: 133988188160.0000 - val_loss: 217796928034.1333 - val_mae: 258217.7656 - val_mse: 202429480960.0000\n",
            "Epoch 51/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 134017408032.9888 - mae: 244442.3438 - mse: 133565743104.0000 - val_loss: 215851654621.8667 - val_mae: 258803.1250 - val_mse: 202113712128.0000\n",
            "Epoch 52/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136607230496.8988 - mae: 248044.6719 - mse: 136515403776.0000 - val_loss: 219144153224.5333 - val_mae: 256320.0156 - val_mse: 202934091776.0000\n",
            "Epoch 53/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134598485339.3732 - mae: 243762.5312 - mse: 133495422976.0000 - val_loss: 215566896332.8000 - val_mae: 260566.0156 - val_mse: 203034263552.0000\n",
            "Epoch 54/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132752966290.2228 - mae: 242318.2031 - mse: 132279820288.0000 - val_loss: 215527126903.4667 - val_mae: 263780.4688 - val_mse: 203416780800.0000\n",
            "Epoch 55/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133340295817.0871 - mae: 243535.6719 - mse: 132830658560.0000 - val_loss: 217603375104.0000 - val_mae: 255309.5938 - val_mse: 202422370304.0000\n",
            "Epoch 56/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131838696410.1780 - mae: 241689.4375 - mse: 131492093952.0000 - val_loss: 215664536780.8000 - val_mae: 262048.7656 - val_mse: 201672146944.0000\n",
            "Epoch 57/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132253029692.4409 - mae: 242514.6875 - mse: 132247560192.0000 - val_loss: 214719365666.1333 - val_mae: 261632.9375 - val_mse: 201611362304.0000\n",
            "Epoch 58/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131394280006.8820 - mae: 244015.7344 - mse: 132517609472.0000 - val_loss: 213910104746.6667 - val_mae: 263105.7500 - val_mse: 201861709824.0000\n",
            "Epoch 59/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133963460253.9077 - mae: 244997.8125 - mse: 133789589504.0000 - val_loss: 226090530133.3333 - val_mae: 258284.2031 - val_mse: 208055762944.0000\n",
            "Epoch 60/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132424393269.0466 - mae: 242611.8125 - mse: 132759846912.0000 - val_loss: 215044583697.0667 - val_mae: 257679.2188 - val_mse: 201249472512.0000\n",
            "Epoch 61/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132179724397.8365 - mae: 242258.1094 - mse: 132629569536.0000 - val_loss: 215845061700.2667 - val_mae: 265854.1875 - val_mse: 201923559424.0000\n",
            "Epoch 62/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133862657825.2187 - mae: 245227.2500 - mse: 133497421824.0000 - val_loss: 217397694737.0667 - val_mae: 257584.2188 - val_mse: 202048700416.0000\n",
            "Epoch 63/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132160101018.1264 - mae: 242299.6719 - mse: 132077363200.0000 - val_loss: 214495579886.9333 - val_mae: 261221.3750 - val_mse: 201410527232.0000\n",
            "Epoch 64/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130947667842.4320 - mae: 242380.8906 - mse: 131922681856.0000 - val_loss: 214545961233.0667 - val_mae: 259293.3594 - val_mse: 201572368384.0000\n",
            "Epoch 65/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132080821558.7168 - mae: 243051.9844 - mse: 132889542656.0000 - val_loss: 216049516544.0000 - val_mae: 256818.2656 - val_mse: 201102049280.0000\n",
            "Epoch 66/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132997056443.6720 - mae: 242838.7500 - mse: 133039267840.0000 - val_loss: 213990134033.0667 - val_mae: 259114.0625 - val_mse: 200885846016.0000\n",
            "Epoch 67/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134078786073.5069 - mae: 243672.5469 - mse: 133487173632.0000 - val_loss: 215820120337.0667 - val_mae: 262841.6250 - val_mse: 202929422336.0000\n",
            "Epoch 68/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131980464115.2252 - mae: 241331.8281 - mse: 131428999168.0000 - val_loss: 215026402918.4000 - val_mae: 265219.2500 - val_mse: 202722377728.0000\n",
            "Epoch 69/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133077038821.9127 - mae: 244606.9375 - mse: 133281128448.0000 - val_loss: 214139663155.2000 - val_mae: 259054.7812 - val_mse: 199915094016.0000\n",
            "Epoch 70/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131466128094.7766 - mae: 242544.6094 - mse: 132163444736.0000 - val_loss: 214915980219.7333 - val_mae: 256475.1406 - val_mse: 200954183680.0000\n",
            "Epoch 71/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132286323663.8293 - mae: 242308.8906 - mse: 131889840128.0000 - val_loss: 218042047965.8667 - val_mae: 271174.0000 - val_mse: 206871494656.0000\n",
            "Epoch 72/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132263541321.5734 - mae: 243239.1250 - mse: 132944044032.0000 - val_loss: 216693613090.1333 - val_mae: 255426.4375 - val_mse: 201667428352.0000\n",
            "Epoch 73/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133377130140.5430 - mae: 244043.1719 - mse: 133232656384.0000 - val_loss: 215154860032.0000 - val_mae: 262301.1562 - val_mse: 202610343936.0000\n",
            "Epoch 74/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130730087714.5502 - mae: 243323.4688 - mse: 131964264448.0000 - val_loss: 216189954184.5333 - val_mae: 255980.7656 - val_mse: 202621927424.0000\n",
            "Epoch 75/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 135698334723.2126 - mae: 246500.1875 - mse: 135542939648.0000 - val_loss: 220339521126.4000 - val_mae: 267683.0000 - val_mse: 206225539072.0000\n",
            "Epoch 76/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131847555023.0048 - mae: 242539.4688 - mse: 131915046912.0000 - val_loss: 216403078894.9333 - val_mae: 265809.8750 - val_mse: 203346280448.0000\n",
            "Epoch 77/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132047482833.1844 - mae: 242971.3438 - mse: 132434608128.0000 - val_loss: 226253807616.0000 - val_mae: 261601.4688 - val_mse: 210032836608.0000\n",
            "Epoch 78/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133820497672.8064 - mae: 244216.7344 - mse: 133357797376.0000 - val_loss: 218425030519.4667 - val_mae: 255621.1719 - val_mse: 202651172864.0000\n",
            "Epoch 79/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130903788022.7838 - mae: 242301.7031 - mse: 132133756928.0000 - val_loss: 215926503833.6000 - val_mae: 267009.3750 - val_mse: 203625775104.0000\n",
            "Epoch 80/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132277441148.1986 - mae: 243485.2812 - mse: 132293459968.0000 - val_loss: 217159149704.5333 - val_mae: 256297.1406 - val_mse: 202089562112.0000\n",
            "Epoch 81/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132951483930.1987 - mae: 242788.2188 - mse: 132623351808.0000 - val_loss: 214737959867.7333 - val_mae: 257807.5938 - val_mse: 201318662144.0000\n",
            "Epoch 82/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133380704638.4280 - mae: 242493.2500 - mse: 132129423360.0000 - val_loss: 216488166468.2667 - val_mae: 255451.2500 - val_mse: 201075245056.0000\n",
            "Epoch 83/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131346105106.0083 - mae: 240955.4375 - mse: 131669835776.0000 - val_loss: 213865012155.7333 - val_mae: 257435.7969 - val_mse: 200020819968.0000\n",
            "Epoch 84/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133072811451.1650 - mae: 242129.5156 - mse: 132531937280.0000 - val_loss: 215115936563.2000 - val_mae: 257761.4219 - val_mse: 200246968320.0000\n",
            "Epoch 85/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132520301152.6779 - mae: 242307.5625 - mse: 131751387136.0000 - val_loss: 214165482154.6667 - val_mae: 264071.8438 - val_mse: 201383084032.0000\n",
            "Epoch 86/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130535461882.3802 - mae: 241903.6562 - mse: 131479052288.0000 - val_loss: 216975351261.8667 - val_mae: 268481.1562 - val_mse: 205235290112.0000\n",
            "Epoch 87/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132640290579.1740 - mae: 243073.3906 - mse: 131938942976.0000 - val_loss: 214869047159.4667 - val_mae: 266866.5000 - val_mse: 202684137472.0000\n",
            "Epoch 88/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132294135755.3467 - mae: 242256.9375 - mse: 132055826432.0000 - val_loss: 217456999355.7333 - val_mae: 254930.0781 - val_mse: 201691250688.0000\n",
            "Epoch 89/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132509789694.3937 - mae: 243357.8281 - mse: 132598915072.0000 - val_loss: 218722061516.8000 - val_mae: 256469.2812 - val_mse: 202658430976.0000\n",
            "Epoch 90/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133378830669.5465 - mae: 243837.2812 - mse: 133141168128.0000 - val_loss: 214078948420.2667 - val_mae: 259774.8906 - val_mse: 201039118336.0000\n",
            "Epoch 91/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131504349913.7160 - mae: 241208.4062 - mse: 131145965568.0000 - val_loss: 214239523635.2000 - val_mae: 258751.6875 - val_mse: 201116794880.0000\n",
            "Epoch 92/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132658822447.0785 - mae: 242932.5938 - mse: 132561567744.0000 - val_loss: 214465752268.8000 - val_mae: 264265.5000 - val_mse: 201881747456.0000\n",
            "Epoch 93/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129889080392.7726 - mae: 241404.7969 - mse: 130644688896.0000 - val_loss: 215633135206.4000 - val_mae: 255431.5312 - val_mse: 200710995968.0000\n",
            "Epoch 94/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130807696041.3273 - mae: 240554.5000 - mse: 130557517824.0000 - val_loss: 215413488025.6000 - val_mae: 266854.6562 - val_mse: 204008751104.0000\n",
            "Epoch 95/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131751124140.6773 - mae: 241830.0000 - mse: 131823886336.0000 - val_loss: 215243054557.8667 - val_mae: 265254.3750 - val_mse: 203310481408.0000\n",
            "Epoch 96/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132321797497.0926 - mae: 241810.5625 - mse: 131647668224.0000 - val_loss: 216626942771.2000 - val_mae: 255510.7812 - val_mse: 200754511872.0000\n",
            "Epoch 97/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131277936068.4523 - mae: 242340.5312 - mse: 132198572032.0000 - val_loss: 218176349252.2667 - val_mae: 254531.5312 - val_mse: 202305765376.0000\n",
            "Epoch 98/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131577725055.1791 - mae: 242915.0625 - mse: 131898900480.0000 - val_loss: 218341884996.2667 - val_mae: 254849.4375 - val_mse: 202412703744.0000\n",
            "Epoch 99/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132930537119.6704 - mae: 242833.6719 - mse: 132246118400.0000 - val_loss: 213656363008.0000 - val_mae: 259940.0000 - val_mse: 200062517248.0000\n",
            "Epoch 100/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131272166340.6087 - mae: 240902.7344 - mse: 130742083584.0000 - val_loss: 213350591146.6667 - val_mae: 257663.6250 - val_mse: 199926054912.0000\n",
            "Epoch 101/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132091469553.8724 - mae: 242710.4375 - mse: 131558047744.0000 - val_loss: 219367559987.2000 - val_mae: 255301.6406 - val_mse: 203197612032.0000\n",
            "Epoch 102/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131796923812.6481 - mae: 241654.8125 - mse: 131645333504.0000 - val_loss: 215175124309.3333 - val_mae: 262883.0312 - val_mse: 201747218432.0000\n",
            "Epoch 103/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129264678173.4706 - mae: 240876.3750 - mse: 130955132928.0000 - val_loss: 215408304128.0000 - val_mae: 268649.2500 - val_mse: 203135172608.0000\n",
            "Epoch 104/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132511236092.9674 - mae: 243285.9375 - mse: 132262199296.0000 - val_loss: 213600775372.8000 - val_mae: 255731.1719 - val_mse: 199932837888.0000\n",
            "Epoch 105/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132476471727.6696 - mae: 241130.0625 - mse: 131728105472.0000 - val_loss: 213457124829.8667 - val_mae: 256032.3750 - val_mse: 199629242368.0000\n",
            "Epoch 106/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131305853364.5786 - mae: 241833.6406 - mse: 131858194432.0000 - val_loss: 216861614080.0000 - val_mae: 270557.2812 - val_mse: 204377112576.0000\n",
            "Epoch 107/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130912668047.7896 - mae: 240879.1875 - mse: 130762391552.0000 - val_loss: 215661917525.3333 - val_mae: 266337.8750 - val_mse: 203353210880.0000\n",
            "Epoch 108/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132766048025.5614 - mae: 243481.9219 - mse: 132270497792.0000 - val_loss: 213654246741.3333 - val_mae: 259375.7344 - val_mse: 201147727872.0000\n",
            "Epoch 109/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133155113310.0552 - mae: 242167.3281 - mse: 132480802816.0000 - val_loss: 213831726421.3333 - val_mae: 256337.1719 - val_mse: 199537557504.0000\n",
            "Epoch 110/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131855497814.1586 - mae: 241748.2656 - mse: 131110486016.0000 - val_loss: 217361468074.6667 - val_mae: 268134.2500 - val_mse: 206753251328.0000\n",
            "Epoch 111/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132431737179.4206 - mae: 242177.0781 - mse: 131672031232.0000 - val_loss: 215833689565.8667 - val_mae: 269157.3125 - val_mse: 204625362944.0000\n",
            "Epoch 112/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131505153128.6526 - mae: 242012.4219 - mse: 132229668864.0000 - val_loss: 213194390459.7333 - val_mae: 258824.7344 - val_mse: 199522107392.0000\n",
            "Epoch 113/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133418162714.3409 - mae: 242673.0312 - mse: 132177305600.0000 - val_loss: 214995046673.0667 - val_mae: 263223.0312 - val_mse: 202350641152.0000\n",
            "Epoch 114/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130558152147.7100 - mae: 241644.2812 - mse: 131413835776.0000 - val_loss: 214877098257.0667 - val_mae: 254729.2656 - val_mse: 200174485504.0000\n",
            "Epoch 115/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132763882718.2032 - mae: 242884.7656 - mse: 131720413184.0000 - val_loss: 226410083123.2000 - val_mae: 262656.7188 - val_mse: 210391744512.0000\n",
            "Epoch 116/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130978898880.7990 - mae: 242167.0469 - mse: 131952533504.0000 - val_loss: 222292854374.4000 - val_mae: 253771.7969 - val_mse: 204546801664.0000\n",
            "Epoch 117/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131632749102.6213 - mae: 242108.4062 - mse: 131187679232.0000 - val_loss: 214485796454.4000 - val_mae: 255132.3750 - val_mse: 200333312000.0000\n",
            "Epoch 118/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131317423434.7888 - mae: 241245.9219 - mse: 130961514496.0000 - val_loss: 215915301546.6667 - val_mae: 255405.5312 - val_mse: 201461514240.0000\n",
            "Epoch 119/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129853917615.7455 - mae: 240881.5781 - mse: 130921250816.0000 - val_loss: 214195693704.5333 - val_mae: 260801.1719 - val_mse: 200809021440.0000\n",
            "Epoch 120/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130977670311.6546 - mae: 243442.9844 - mse: 131191316480.0000 - val_loss: 219634769373.8667 - val_mae: 256095.0625 - val_mse: 203924324352.0000\n",
            "Epoch 121/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131812348128.1081 - mae: 240407.6406 - mse: 130935635968.0000 - val_loss: 214403916868.2667 - val_mae: 255661.4062 - val_mse: 199927644160.0000\n",
            "Epoch 122/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130185118835.5320 - mae: 242406.0781 - mse: 130980077568.0000 - val_loss: 218313044241.0667 - val_mae: 253518.6719 - val_mse: 202224451584.0000\n",
            "Epoch 123/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132354190139.7254 - mae: 243723.4375 - mse: 132475043840.0000 - val_loss: 216285218406.4000 - val_mae: 270910.9062 - val_mse: 204851675136.0000\n",
            "Epoch 124/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131030018890.2059 - mae: 241644.1094 - mse: 130516779008.0000 - val_loss: 214195552256.0000 - val_mae: 258149.9844 - val_mse: 199954710528.0000\n",
            "Epoch 125/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129146247005.5103 - mae: 239613.7656 - mse: 130063941632.0000 - val_loss: 215323804194.1333 - val_mae: 253808.5781 - val_mse: 199831339008.0000\n",
            "Epoch 126/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126921579520.3885 - mae: 240015.0156 - mse: 129856593920.0000 - val_loss: 212808854186.6667 - val_mae: 258363.8438 - val_mse: 200602025984.0000\n",
            "Epoch 127/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131586103310.3858 - mae: 241893.2188 - mse: 130940624896.0000 - val_loss: 215461600733.8667 - val_mae: 254908.2188 - val_mse: 200256438272.0000\n",
            "Epoch 128/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131024206653.3175 - mae: 241528.7969 - mse: 130579677184.0000 - val_loss: 215988829661.8667 - val_mae: 254591.0625 - val_mse: 200449851392.0000\n",
            "Epoch 129/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133495391118.3065 - mae: 243647.9219 - mse: 133392097280.0000 - val_loss: 213795452791.4667 - val_mae: 256349.2500 - val_mse: 199162118144.0000\n",
            "Epoch 130/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130440806608.4145 - mae: 241059.9062 - mse: 130995167232.0000 - val_loss: 217670140450.1333 - val_mae: 268117.1875 - val_mse: 204949274624.0000\n",
            "Epoch 131/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130757031830.8640 - mae: 240872.4844 - mse: 130284527616.0000 - val_loss: 212816217702.4000 - val_mae: 260472.7812 - val_mse: 199622541312.0000\n",
            "Epoch 132/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130227522277.4862 - mae: 240919.4062 - mse: 129906024448.0000 - val_loss: 212908163618.1333 - val_mae: 257975.1562 - val_mse: 200059453440.0000\n",
            "Epoch 133/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128257526096.0674 - mae: 240102.1875 - mse: 130170429440.0000 - val_loss: 216208500326.4000 - val_mae: 253700.0312 - val_mse: 200637906944.0000\n",
            "Epoch 134/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133627499378.6720 - mae: 243854.1562 - mse: 132679204864.0000 - val_loss: 213489109128.5333 - val_mae: 258869.2188 - val_mse: 199425982464.0000\n",
            "Epoch 135/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130030820156.8247 - mae: 240485.4688 - mse: 129718362112.0000 - val_loss: 214729961198.9333 - val_mae: 254887.7812 - val_mse: 200067137536.0000\n",
            "Epoch 136/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131865570318.8691 - mae: 241796.8594 - mse: 131343089664.0000 - val_loss: 215814769868.8000 - val_mae: 270488.9375 - val_mse: 204245336064.0000\n",
            "Epoch 137/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130721864930.9606 - mae: 241825.6562 - mse: 130887417856.0000 - val_loss: 216177778141.8667 - val_mae: 253636.6562 - val_mse: 200376123392.0000\n",
            "Epoch 138/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130715517671.5142 - mae: 240705.4531 - mse: 130394013696.0000 - val_loss: 214921834222.9333 - val_mae: 256820.4062 - val_mse: 201982296064.0000\n",
            "Epoch 139/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131826485419.9287 - mae: 242214.3281 - mse: 131222388736.0000 - val_loss: 213047978666.6667 - val_mae: 262911.4375 - val_mse: 200804777984.0000\n",
            "Epoch 140/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 136064420237.3635 - mae: 246400.9531 - mse: 135070351360.0000 - val_loss: 215303855581.8667 - val_mae: 268489.7812 - val_mse: 203951390720.0000\n",
            "Epoch 141/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 133161210412.1004 - mae: 243318.7969 - mse: 132092477440.0000 - val_loss: 214653725354.6667 - val_mae: 255045.5625 - val_mse: 199880048640.0000\n",
            "Epoch 142/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131596226226.9842 - mae: 241054.9688 - mse: 131127967744.0000 - val_loss: 215394923861.3333 - val_mae: 254861.8125 - val_mse: 200412004352.0000\n",
            "Epoch 143/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130496270136.5317 - mae: 239933.1094 - mse: 129574461440.0000 - val_loss: 214866621235.2000 - val_mae: 255079.6719 - val_mse: 200998354944.0000\n",
            "Epoch 144/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130179782036.8786 - mae: 240444.9219 - mse: 130232033280.0000 - val_loss: 219175801651.2000 - val_mae: 274678.0625 - val_mse: 207604760576.0000\n",
            "Epoch 145/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132342696434.6898 - mae: 241726.5781 - mse: 131792486400.0000 - val_loss: 213088290952.5333 - val_mae: 257944.1406 - val_mse: 200104443904.0000\n",
            "Epoch 146/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130405195329.1106 - mae: 239171.4844 - mse: 129644732416.0000 - val_loss: 214024993177.6000 - val_mae: 258768.1875 - val_mse: 200637874176.0000\n",
            "Epoch 147/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130533661130.8492 - mae: 240696.3750 - mse: 130486444032.0000 - val_loss: 213109124300.8000 - val_mae: 259739.5938 - val_mse: 200341766144.0000\n",
            "Epoch 148/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132915984967.1852 - mae: 243075.5781 - mse: 132824563712.0000 - val_loss: 212925331865.6000 - val_mae: 255429.8281 - val_mse: 198837944320.0000\n",
            "Epoch 149/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130395207451.6652 - mae: 240124.5781 - mse: 129815109632.0000 - val_loss: 213755477469.8667 - val_mae: 254857.5156 - val_mse: 199199211520.0000\n",
            "Epoch 150/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133327113396.0314 - mae: 243365.9688 - mse: 132642185216.0000 - val_loss: 222727654604.8000 - val_mae: 255347.2188 - val_mse: 205212958720.0000\n",
            "Epoch 151/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131355631147.6171 - mae: 240993.3906 - mse: 130924912640.0000 - val_loss: 214142193937.0667 - val_mae: 265181.6875 - val_mse: 201585475584.0000\n",
            "Epoch 152/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130231326360.3922 - mae: 240473.3750 - mse: 129743855616.0000 - val_loss: 215294669619.2000 - val_mae: 253919.9062 - val_mse: 201284501504.0000\n",
            "Epoch 153/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131902844001.7725 - mae: 241468.2500 - mse: 130955616256.0000 - val_loss: 215572355481.6000 - val_mae: 257408.9688 - val_mse: 201646391296.0000\n",
            "Epoch 154/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131545500940.2038 - mae: 241733.7031 - mse: 132261961728.0000 - val_loss: 215466128179.2000 - val_mae: 259372.4688 - val_mse: 202245849088.0000\n",
            "Epoch 155/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130017263708.4939 - mae: 240237.6094 - mse: 129608613888.0000 - val_loss: 214478265275.7333 - val_mae: 254799.1875 - val_mse: 199234748416.0000\n",
            "Epoch 156/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132046367438.6660 - mae: 242329.1250 - mse: 131306946560.0000 - val_loss: 213534391773.8667 - val_mae: 255026.7188 - val_mse: 199723499520.0000\n",
            "Epoch 157/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129782020505.3043 - mae: 239472.1719 - mse: 129321574400.0000 - val_loss: 217131090466.1333 - val_mae: 252498.6406 - val_mse: 201167945728.0000\n",
            "Epoch 158/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129779052250.1803 - mae: 240880.8594 - mse: 130148270080.0000 - val_loss: 213272009659.7333 - val_mae: 263030.1562 - val_mse: 201258991616.0000\n",
            "Epoch 159/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130178083226.6311 - mae: 239859.8750 - mse: 129708769280.0000 - val_loss: 214868449689.6000 - val_mae: 253810.3594 - val_mse: 199859372032.0000\n",
            "Epoch 160/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129426009645.2471 - mae: 239205.0312 - mse: 128982106112.0000 - val_loss: 216409525452.8000 - val_mae: 272187.6875 - val_mse: 204917932032.0000\n",
            "Epoch 161/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130949784346.0068 - mae: 240329.1719 - mse: 130390532096.0000 - val_loss: 215825853644.8000 - val_mae: 253203.1562 - val_mse: 200611872768.0000\n",
            "Epoch 162/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127140110059.9210 - mae: 238193.2500 - mse: 128839794688.0000 - val_loss: 215041683729.0667 - val_mae: 263265.4062 - val_mse: 203128225792.0000\n",
            "Epoch 163/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130751990474.1171 - mae: 240897.8906 - mse: 130432368640.0000 - val_loss: 216794492108.8000 - val_mae: 255373.5312 - val_mse: 201778937856.0000\n",
            "Epoch 164/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128962094774.4148 - mae: 239523.8125 - mse: 129083539456.0000 - val_loss: 218775817966.9333 - val_mae: 253322.5312 - val_mse: 202556489728.0000\n",
            "Epoch 165/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129163723334.3323 - mae: 240190.6562 - mse: 129775550464.0000 - val_loss: 215241150190.9333 - val_mae: 253040.7031 - val_mse: 200341979136.0000\n",
            "Epoch 166/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129039654203.7775 - mae: 239880.1719 - mse: 129465769984.0000 - val_loss: 217905196782.9333 - val_mae: 253731.0156 - val_mse: 202205233152.0000\n",
            "Epoch 167/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132143096566.3739 - mae: 242651.9375 - mse: 132487151616.0000 - val_loss: 217086123485.8667 - val_mae: 252496.3125 - val_mse: 201159884800.0000\n",
            "Epoch 168/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129683989924.4965 - mae: 239781.8125 - mse: 130016182272.0000 - val_loss: 216391918114.1333 - val_mae: 254967.0625 - val_mse: 200865562624.0000\n",
            "Epoch 169/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129638550153.0302 - mae: 240920.4688 - mse: 130008031232.0000 - val_loss: 213652008140.8000 - val_mae: 257627.6094 - val_mse: 199498022912.0000\n",
            "Epoch 170/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130252966991.5390 - mae: 239740.3750 - mse: 130033917952.0000 - val_loss: 215309646233.6000 - val_mae: 255006.6719 - val_mse: 201057632256.0000\n",
            "Epoch 171/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131995597028.0694 - mae: 242521.1094 - mse: 131826941952.0000 - val_loss: 212250161971.2000 - val_mae: 257612.2188 - val_mse: 199052279808.0000\n",
            "Epoch 172/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129728710401.0543 - mae: 240739.7344 - mse: 130009956352.0000 - val_loss: 213937121416.5333 - val_mae: 254783.6406 - val_mse: 199066451968.0000\n",
            "Epoch 173/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130474843317.0169 - mae: 239782.0625 - mse: 129521041408.0000 - val_loss: 216418584712.5333 - val_mae: 253241.2656 - val_mse: 199927529472.0000\n",
            "Epoch 174/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 131659842627.5414 - mae: 241047.2500 - mse: 131731546112.0000 - val_loss: 213671402973.8667 - val_mae: 259738.2188 - val_mse: 199450918912.0000\n",
            "Epoch 175/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129533369453.8270 - mae: 239348.2969 - mse: 129315397632.0000 - val_loss: 211809219925.3333 - val_mae: 256780.7656 - val_mse: 198415728640.0000\n",
            "Epoch 176/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131061728950.6422 - mae: 242078.8594 - mse: 130308866048.0000 - val_loss: 224481169681.0667 - val_mae: 256660.6562 - val_mse: 207869591552.0000\n",
            "Epoch 177/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132252992894.7408 - mae: 244025.4688 - mse: 131925303296.0000 - val_loss: 212252175564.8000 - val_mae: 260374.7969 - val_mse: 200747876352.0000\n",
            "Epoch 178/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132291220273.3198 - mae: 241771.2500 - mse: 132222500864.0000 - val_loss: 215519570056.5333 - val_mae: 269385.1562 - val_mse: 204674334720.0000\n",
            "Epoch 179/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130436579601.5392 - mae: 240416.0781 - mse: 129821556736.0000 - val_loss: 211804227174.4000 - val_mae: 256200.6562 - val_mse: 198914916352.0000\n",
            "Epoch 180/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130014973632.7445 - mae: 238654.7656 - mse: 129220034560.0000 - val_loss: 214153805824.0000 - val_mae: 253174.0469 - val_mse: 199324041216.0000\n",
            "Epoch 181/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127782589856.1750 - mae: 239900.8125 - mse: 129047322624.0000 - val_loss: 214769786333.8667 - val_mae: 268779.7812 - val_mse: 203443699712.0000\n",
            "Epoch 182/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129925851113.9948 - mae: 240282.7344 - mse: 129647058944.0000 - val_loss: 212082569489.0667 - val_mae: 257064.9062 - val_mse: 198163464192.0000\n",
            "Epoch 183/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129145703017.4913 - mae: 238061.6094 - mse: 129018839040.0000 - val_loss: 218434334446.9333 - val_mae: 275511.0000 - val_mse: 206559739904.0000\n",
            "Epoch 184/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130615309656.3407 - mae: 241111.3125 - mse: 129556627456.0000 - val_loss: 214015477896.5333 - val_mae: 263034.9062 - val_mse: 201939091456.0000\n",
            "Epoch 185/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128940647465.7644 - mae: 239721.8594 - mse: 129310605312.0000 - val_loss: 213969594504.5333 - val_mae: 260112.2031 - val_mse: 201407954944.0000\n",
            "Epoch 186/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129517974720.3323 - mae: 239276.2969 - mse: 129001455616.0000 - val_loss: 220805209019.7333 - val_mae: 254686.0000 - val_mse: 204795084800.0000\n",
            "Epoch 187/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130480004473.3011 - mae: 240083.5469 - mse: 130179006464.0000 - val_loss: 214797601450.6667 - val_mae: 253244.8281 - val_mse: 199469203456.0000\n",
            "Epoch 188/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129591969524.5449 - mae: 239357.7344 - mse: 129088389120.0000 - val_loss: 212883687014.4000 - val_mae: 258193.1250 - val_mse: 199164297216.0000\n",
            "Epoch 189/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130080787073.0697 - mae: 240874.7812 - mse: 130220826624.0000 - val_loss: 213582081774.9333 - val_mae: 264707.5000 - val_mse: 202181787648.0000\n",
            "Epoch 190/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130731387372.1697 - mae: 240175.8906 - mse: 130200625152.0000 - val_loss: 214224147797.3333 - val_mae: 257421.8594 - val_mse: 200559443968.0000\n",
            "Epoch 191/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 130151247318.1740 - mae: 239338.6250 - mse: 129370185728.0000 - val_loss: 213410097288.5333 - val_mae: 265033.8125 - val_mse: 201857155072.0000\n",
            "Epoch 192/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127867227655.7947 - mae: 237960.3281 - mse: 128640172032.0000 - val_loss: 212012690636.8000 - val_mae: 260048.8594 - val_mse: 199527890944.0000\n",
            "Epoch 193/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130295280064.9743 - mae: 240133.0000 - mse: 130239504384.0000 - val_loss: 213025570269.8667 - val_mae: 254744.6406 - val_mse: 199135330304.0000\n",
            "Epoch 194/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128339249029.7678 - mae: 237396.8281 - mse: 128455557120.0000 - val_loss: 211945968435.2000 - val_mae: 256995.6250 - val_mse: 199978500096.0000\n",
            "Epoch 195/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129243439467.7587 - mae: 239169.9219 - mse: 128933462016.0000 - val_loss: 212618577510.4000 - val_mae: 263326.3750 - val_mse: 200937652224.0000\n",
            "Epoch 196/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128208446070.0576 - mae: 240932.6875 - mse: 129791713280.0000 - val_loss: 213773790958.9333 - val_mae: 254099.9219 - val_mse: 199780827136.0000\n",
            "Epoch 197/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 132233318952.8025 - mae: 242276.4688 - mse: 131447750656.0000 - val_loss: 214304469811.2000 - val_mae: 255361.7969 - val_mse: 200128184320.0000\n",
            "Epoch 198/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129360771839.0736 - mae: 239612.5312 - mse: 128759332864.0000 - val_loss: 215706105173.3333 - val_mae: 251402.8750 - val_mse: 200344518656.0000\n",
            "Epoch 199/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128126363813.4086 - mae: 239342.8281 - mse: 129065943040.0000 - val_loss: 214713284471.4667 - val_mae: 251844.7031 - val_mse: 199889174528.0000\n",
            "Epoch 200/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128848909881.9271 - mae: 237900.2031 - mse: 128586645504.0000 - val_loss: 212446633984.0000 - val_mae: 254734.8594 - val_mse: 198980845568.0000\n",
            "Epoch 201/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128481331497.7052 - mae: 238994.5312 - mse: 128742842368.0000 - val_loss: 216752083763.2000 - val_mae: 251762.8125 - val_mse: 200634155008.0000\n",
            "Epoch 202/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128771700886.1320 - mae: 239008.0469 - mse: 128420560896.0000 - val_loss: 212510651733.3333 - val_mae: 256578.2656 - val_mse: 197918982144.0000\n",
            "Epoch 203/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 128441173477.5075 - mae: 238455.0000 - mse: 127822741504.0000 - val_loss: 212666968746.6667 - val_mae: 254723.0156 - val_mse: 199020085248.0000\n",
            "Epoch 204/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129708929258.4947 - mae: 239508.3906 - mse: 129288003584.0000 - val_loss: 216329531665.0667 - val_mae: 270255.7188 - val_mse: 203167727616.0000\n",
            "Epoch 205/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128283962783.7770 - mae: 238633.1875 - mse: 128657227776.0000 - val_loss: 213377024546.1333 - val_mae: 264977.2500 - val_mse: 201844703232.0000\n",
            "Epoch 206/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 129174325392.1047 - mae: 238160.1250 - mse: 127912812544.0000 - val_loss: 212443228296.5333 - val_mae: 255964.2812 - val_mse: 198728269824.0000\n",
            "Epoch 207/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129863945004.9794 - mae: 241125.5469 - mse: 129619656704.0000 - val_loss: 225389585476.2667 - val_mae: 254991.6406 - val_mse: 208117727232.0000\n",
            "Epoch 208/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129533116699.9258 - mae: 239361.4375 - mse: 129563000832.0000 - val_loss: 213355548945.0667 - val_mae: 255255.3750 - val_mse: 198674710528.0000\n",
            "Epoch 209/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129321040851.0893 - mae: 238232.6875 - mse: 128495763456.0000 - val_loss: 211213373713.0667 - val_mae: 256704.6094 - val_mse: 198579732480.0000\n",
            "Epoch 210/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128420166051.8805 - mae: 238419.0000 - mse: 128531513344.0000 - val_loss: 211512225518.9333 - val_mae: 256143.1719 - val_mse: 198388006912.0000\n",
            "Epoch 211/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128879894970.6438 - mae: 238659.7969 - mse: 128642064384.0000 - val_loss: 221961551325.8667 - val_mae: 255137.0625 - val_mse: 205313982464.0000\n",
            "Epoch 212/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127249643392.4987 - mae: 238122.7031 - mse: 128024453120.0000 - val_loss: 217562182451.2000 - val_mae: 276653.4062 - val_mse: 207094153216.0000\n",
            "Epoch 213/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127454695416.9492 - mae: 238216.9062 - mse: 128238895104.0000 - val_loss: 213024391714.1333 - val_mae: 264843.4688 - val_mse: 202121838592.0000\n",
            "Epoch 214/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130404242749.0095 - mae: 241796.1875 - mse: 130579562496.0000 - val_loss: 212003090158.9333 - val_mae: 258126.0000 - val_mse: 200231616512.0000\n",
            "Epoch 215/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131838442016.9367 - mae: 244403.5156 - mse: 132862214144.0000 - val_loss: 217367656857.6000 - val_mae: 268899.3438 - val_mse: 204222300160.0000\n",
            "Epoch 216/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 133706563996.0526 - mae: 245823.5625 - mse: 133990785024.0000 - val_loss: 214557081600.0000 - val_mae: 267290.5625 - val_mse: 202433527808.0000\n",
            "Epoch 217/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 132718261256.0269 - mae: 246204.3906 - mse: 133391196160.0000 - val_loss: 213934310468.2667 - val_mae: 253958.7500 - val_mse: 199600668672.0000\n",
            "Epoch 218/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130108149919.3624 - mae: 240015.8906 - mse: 129671389184.0000 - val_loss: 215512322867.2000 - val_mae: 268266.4062 - val_mse: 203300143104.0000\n",
            "Epoch 219/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131874759210.3946 - mae: 242398.1719 - mse: 131384508416.0000 - val_loss: 213977697484.8000 - val_mae: 266867.1250 - val_mse: 202866196480.0000\n",
            "Epoch 220/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131242844671.0286 - mae: 242688.7188 - mse: 132101111808.0000 - val_loss: 213816495854.9333 - val_mae: 252141.6562 - val_mse: 198716260352.0000\n",
            "Epoch 221/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130707088964.6928 - mae: 240117.8750 - mse: 129840603136.0000 - val_loss: 211293097710.9333 - val_mae: 260158.0938 - val_mse: 198698139648.0000\n",
            "Epoch 222/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128961193501.8757 - mae: 239579.7031 - mse: 129407590400.0000 - val_loss: 216906277956.2667 - val_mae: 252598.8906 - val_mse: 200139259904.0000\n",
            "Epoch 223/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129580788526.3062 - mae: 241110.4219 - mse: 129894359040.0000 - val_loss: 215897255116.8000 - val_mae: 266031.7188 - val_mse: 202830102528.0000\n",
            "Epoch 224/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128465262227.6917 - mae: 237767.2656 - mse: 127874260992.0000 - val_loss: 211383351159.4667 - val_mae: 254655.4375 - val_mse: 198400753664.0000\n",
            "Epoch 225/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128495592678.3154 - mae: 236734.8125 - mse: 127586705408.0000 - val_loss: 211822312925.8667 - val_mae: 258878.0625 - val_mse: 198324879360.0000\n",
            "Epoch 226/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128694081545.7611 - mae: 239379.3594 - mse: 128056008704.0000 - val_loss: 212347303253.3333 - val_mae: 255979.9219 - val_mse: 199949467648.0000\n",
            "Epoch 227/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127326086396.1121 - mae: 237058.6719 - mse: 128242728960.0000 - val_loss: 213549388049.0667 - val_mae: 252275.2656 - val_mse: 198784745472.0000\n",
            "Epoch 228/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128314009597.0622 - mae: 238517.1406 - mse: 128105365504.0000 - val_loss: 213436685243.7333 - val_mae: 252416.4062 - val_mse: 198309101568.0000\n",
            "Epoch 229/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128492138176.2517 - mae: 238958.2812 - mse: 128290856960.0000 - val_loss: 211970393702.4000 - val_mae: 253824.7031 - val_mse: 198690865152.0000\n",
            "Epoch 230/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129161629159.4597 - mae: 238675.5938 - mse: 128884006912.0000 - val_loss: 213275267891.2000 - val_mae: 260726.2969 - val_mse: 199921500160.0000\n",
            "Epoch 231/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127908592466.3181 - mae: 239504.7656 - mse: 128758087680.0000 - val_loss: 213773573051.7333 - val_mae: 252710.3750 - val_mse: 199334232064.0000\n",
            "Epoch 232/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128422245484.2159 - mae: 239826.2031 - mse: 129089060864.0000 - val_loss: 217145493640.5333 - val_mae: 252783.5781 - val_mse: 200795553792.0000\n",
            "Epoch 233/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126063524004.9916 - mae: 237692.2344 - mse: 127704498176.0000 - val_loss: 213197536187.7333 - val_mae: 259908.4844 - val_mse: 199479394304.0000\n",
            "Epoch 234/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129421409029.8970 - mae: 238762.2031 - mse: 129285808128.0000 - val_loss: 220882261879.4667 - val_mae: 252890.6875 - val_mse: 204309921792.0000\n",
            "Epoch 235/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127427003060.0361 - mae: 239313.8438 - mse: 128691978240.0000 - val_loss: 212465605563.7333 - val_mae: 262565.5312 - val_mse: 200717320192.0000\n",
            "Epoch 236/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129016784723.2753 - mae: 238241.2500 - mse: 128220848128.0000 - val_loss: 210287358771.2000 - val_mae: 257744.2188 - val_mse: 198421069824.0000\n",
            "Epoch 237/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126001979386.3139 - mae: 238680.7656 - mse: 128054370304.0000 - val_loss: 212394221568.0000 - val_mae: 253422.5000 - val_mse: 199040565248.0000\n",
            "Epoch 238/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131942453385.1487 - mae: 242791.5781 - mse: 131179110400.0000 - val_loss: 212779545941.3333 - val_mae: 257682.2031 - val_mse: 198913736704.0000\n",
            "Epoch 239/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128482120177.5715 - mae: 237974.8438 - mse: 128163299328.0000 - val_loss: 213635182318.9333 - val_mae: 254281.9062 - val_mse: 198937460736.0000\n",
            "Epoch 240/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 134678236154.8162 - mae: 243997.8906 - mse: 133774647296.0000 - val_loss: 211629057092.2667 - val_mae: 256329.9844 - val_mse: 197458493440.0000\n",
            "Epoch 241/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127195566938.0323 - mae: 237004.0312 - mse: 127271018496.0000 - val_loss: 215830358698.6667 - val_mae: 253527.2188 - val_mse: 200385511424.0000\n",
            "Epoch 242/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130379701909.3406 - mae: 239968.1094 - mse: 129410752512.0000 - val_loss: 212051795421.8667 - val_mae: 252786.5469 - val_mse: 198030737408.0000\n",
            "Epoch 243/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 131322484569.7195 - mae: 240819.0000 - mse: 130421448704.0000 - val_loss: 215456061303.4667 - val_mae: 270338.7500 - val_mse: 203935809536.0000\n",
            "Epoch 244/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130031390692.3656 - mae: 240659.2656 - mse: 129518551040.0000 - val_loss: 213286656955.7333 - val_mae: 252897.1094 - val_mse: 198046416896.0000\n",
            "Epoch 245/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129978260635.2779 - mae: 239669.2031 - mse: 129473069056.0000 - val_loss: 212636864785.0667 - val_mae: 252702.9844 - val_mse: 197930778624.0000\n",
            "Epoch 246/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127755038801.4249 - mae: 236993.3594 - mse: 127515435008.0000 - val_loss: 212086850628.2667 - val_mae: 260579.2656 - val_mse: 199097597952.0000\n",
            "Epoch 247/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126856146163.7536 - mae: 236596.4219 - mse: 127201247232.0000 - val_loss: 217394492757.3333 - val_mae: 272859.8750 - val_mse: 204881870848.0000\n",
            "Epoch 248/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130134848052.8570 - mae: 242746.8750 - mse: 130696290304.0000 - val_loss: 211759183735.4667 - val_mae: 253548.3594 - val_mse: 197855756288.0000\n",
            "Epoch 249/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127958282707.7385 - mae: 237476.3281 - mse: 128604594176.0000 - val_loss: 216409104930.1333 - val_mae: 253132.4844 - val_mse: 201136963584.0000\n",
            "Epoch 250/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130233161866.6839 - mae: 238831.3281 - mse: 129491550208.0000 - val_loss: 215659966190.9333 - val_mae: 250492.3750 - val_mse: 200133361664.0000\n",
            "Epoch 251/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128659812149.2337 - mae: 236854.1562 - mse: 127584927744.0000 - val_loss: 216301655381.3333 - val_mae: 251534.8281 - val_mse: 199645757440.0000\n",
            "Epoch 252/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127506023743.2839 - mae: 237135.0469 - mse: 126933557248.0000 - val_loss: 212258652160.0000 - val_mae: 252549.0000 - val_mse: 197874679808.0000\n",
            "Epoch 253/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127748891890.3699 - mae: 237014.0938 - mse: 127349260288.0000 - val_loss: 210913414894.9333 - val_mae: 252807.2656 - val_mse: 197504172032.0000\n",
            "Epoch 254/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127561850175.9094 - mae: 238109.7969 - mse: 128170106880.0000 - val_loss: 214264643037.8667 - val_mae: 250643.8750 - val_mse: 199017086976.0000\n",
            "Epoch 255/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127951064258.4361 - mae: 237796.3594 - mse: 127146631168.0000 - val_loss: 213014898824.5333 - val_mae: 252295.9219 - val_mse: 198404046848.0000\n",
            "Epoch 256/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129108394002.0060 - mae: 238561.6875 - mse: 128256270336.0000 - val_loss: 211810885632.0000 - val_mae: 252376.2188 - val_mse: 197518065664.0000\n",
            "Epoch 257/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128395428988.9331 - mae: 238880.7031 - mse: 128764035072.0000 - val_loss: 213952112776.5333 - val_mae: 255535.5469 - val_mse: 199215677440.0000\n",
            "Epoch 258/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128086903153.0847 - mae: 237352.0000 - mse: 127883378688.0000 - val_loss: 212630309546.6667 - val_mae: 254567.0938 - val_mse: 198876381184.0000\n",
            "Epoch 259/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129104574559.0905 - mae: 239970.5781 - mse: 129339088896.0000 - val_loss: 214578136678.4000 - val_mae: 270668.1250 - val_mse: 203910283264.0000\n",
            "Epoch 260/300\n",
            "57/57 [==============================] - 0s 6ms/step - loss: 126404592778.5418 - mae: 237676.8906 - mse: 128146612224.0000 - val_loss: 211493084091.7333 - val_mae: 257478.8125 - val_mse: 198656835584.0000\n",
            "Epoch 261/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127140438868.0808 - mae: 237821.1406 - mse: 127531753472.0000 - val_loss: 211494526429.8667 - val_mae: 259082.1562 - val_mse: 198591037440.0000\n",
            "Epoch 262/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126063375132.3570 - mae: 236937.3125 - mse: 126718189568.0000 - val_loss: 212146917102.9333 - val_mae: 253644.2344 - val_mse: 198363037696.0000\n",
            "Epoch 263/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127680196684.9519 - mae: 237203.3750 - mse: 127238905856.0000 - val_loss: 210934607598.9333 - val_mae: 253610.8750 - val_mse: 197343608832.0000\n",
            "Epoch 264/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127298633888.0826 - mae: 236988.7969 - mse: 127448522752.0000 - val_loss: 210771175014.4000 - val_mae: 261839.2500 - val_mse: 199764393984.0000\n",
            "Epoch 265/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127957761725.0675 - mae: 237343.9375 - mse: 127903629312.0000 - val_loss: 211944066798.9333 - val_mae: 258900.0469 - val_mse: 199056965632.0000\n",
            "Epoch 266/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128473045917.5642 - mae: 238540.9375 - mse: 127869812736.0000 - val_loss: 210884625476.2667 - val_mae: 261738.9375 - val_mse: 199049887744.0000\n",
            "Epoch 267/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 125924290180.9647 - mae: 238043.4531 - mse: 127376244736.0000 - val_loss: 209932832494.9333 - val_mae: 255653.2188 - val_mse: 197478121472.0000\n",
            "Epoch 268/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130650102371.1608 - mae: 241754.1406 - mse: 130757394432.0000 - val_loss: 213372795835.7333 - val_mae: 266547.4062 - val_mse: 200687828992.0000\n",
            "Epoch 269/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129054917670.9972 - mae: 237993.5312 - mse: 128368164864.0000 - val_loss: 211184988433.0667 - val_mae: 261206.9531 - val_mse: 199328546816.0000\n",
            "Epoch 270/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128169075061.8041 - mae: 238214.1875 - mse: 128223854592.0000 - val_loss: 211698828356.2667 - val_mae: 255425.1406 - val_mse: 198102155264.0000\n",
            "Epoch 271/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127620056312.7384 - mae: 237254.0156 - mse: 128053387264.0000 - val_loss: 211179045410.1333 - val_mae: 252264.0156 - val_mse: 197178589184.0000\n",
            "Epoch 272/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129239854266.8168 - mae: 238725.5312 - mse: 128388734976.0000 - val_loss: 212286311082.6667 - val_mae: 251729.6250 - val_mse: 198239862784.0000\n",
            "Epoch 273/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128528545664.8778 - mae: 238321.0156 - mse: 127933202432.0000 - val_loss: 212891560072.5333 - val_mae: 254732.0156 - val_mse: 198609420288.0000\n",
            "Epoch 274/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128631456345.0585 - mae: 240155.0156 - mse: 128596393984.0000 - val_loss: 214104589380.2667 - val_mae: 253835.2969 - val_mse: 198829506560.0000\n",
            "Epoch 275/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127729192025.3570 - mae: 236678.4375 - mse: 127309512704.0000 - val_loss: 211129675502.9333 - val_mae: 252521.9531 - val_mse: 197097242624.0000\n",
            "Epoch 276/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128882264217.8469 - mae: 238995.8750 - mse: 128067665920.0000 - val_loss: 212817099707.7333 - val_mae: 252177.5312 - val_mse: 198336053248.0000\n",
            "Epoch 277/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126491123175.9525 - mae: 237056.0938 - mse: 126976237568.0000 - val_loss: 215747294003.2000 - val_mae: 253563.4844 - val_mse: 200946761728.0000\n",
            "Epoch 278/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128024746770.4822 - mae: 236914.0938 - mse: 127049826304.0000 - val_loss: 212307037388.8000 - val_mae: 250849.6875 - val_mse: 197559123968.0000\n",
            "Epoch 279/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127440265463.9139 - mae: 237027.6406 - mse: 127322816512.0000 - val_loss: 211674671786.6667 - val_mae: 253578.1250 - val_mse: 197842124800.0000\n",
            "Epoch 280/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127330685005.3689 - mae: 236243.3438 - mse: 127294717952.0000 - val_loss: 213864548488.5333 - val_mae: 252433.6719 - val_mse: 197986729984.0000\n",
            "Epoch 281/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128380658950.1576 - mae: 238107.9062 - mse: 128408674304.0000 - val_loss: 212097909282.1333 - val_mae: 255561.4531 - val_mse: 197943984128.0000\n",
            "Epoch 282/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128304403336.3171 - mae: 236719.6250 - mse: 127236669440.0000 - val_loss: 210950740377.6000 - val_mae: 252956.5156 - val_mse: 197064900608.0000\n",
            "Epoch 283/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129970920317.6841 - mae: 238813.4219 - mse: 129463787520.0000 - val_loss: 214516177305.6000 - val_mae: 252835.6406 - val_mse: 199512817664.0000\n",
            "Epoch 284/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126205194483.7820 - mae: 236360.2969 - mse: 126951235584.0000 - val_loss: 211152438340.2667 - val_mae: 259168.0156 - val_mse: 198534463488.0000\n",
            "Epoch 285/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127791748740.9078 - mae: 237237.7188 - mse: 127694077952.0000 - val_loss: 210713555763.2000 - val_mae: 257483.2812 - val_mse: 198656294912.0000\n",
            "Epoch 286/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128190818209.1369 - mae: 238141.7656 - mse: 127441494016.0000 - val_loss: 214583312930.1333 - val_mae: 250596.0000 - val_mse: 198826672128.0000\n",
            "Epoch 287/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127808086952.5383 - mae: 238707.5938 - mse: 129122385920.0000 - val_loss: 213548940219.7333 - val_mae: 267469.9375 - val_mse: 202209361920.0000\n",
            "Epoch 288/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128063815585.2317 - mae: 237942.8906 - mse: 128045342720.0000 - val_loss: 210727475609.6000 - val_mae: 260252.4062 - val_mse: 197523734528.0000\n",
            "Epoch 289/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127376584917.3803 - mae: 236958.3125 - mse: 127840059392.0000 - val_loss: 210485208132.2667 - val_mae: 255545.5938 - val_mse: 198043189248.0000\n",
            "Epoch 290/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126558182276.8865 - mae: 236310.7812 - mse: 126727741440.0000 - val_loss: 211028674150.4000 - val_mae: 251922.9219 - val_mse: 196746477568.0000\n",
            "Epoch 291/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127261960356.7263 - mae: 237844.8906 - mse: 128215252992.0000 - val_loss: 209969759846.4000 - val_mae: 254544.3750 - val_mse: 197044486144.0000\n",
            "Epoch 292/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 129071622115.9296 - mae: 239627.9688 - mse: 129212497920.0000 - val_loss: 210487715430.4000 - val_mae: 256008.6875 - val_mse: 197167235072.0000\n",
            "Epoch 293/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127194664253.5970 - mae: 238917.5000 - mse: 127720726528.0000 - val_loss: 215072253542.4000 - val_mae: 251303.6562 - val_mse: 199830274048.0000\n",
            "Epoch 294/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 130304332606.8148 - mae: 239528.7812 - mse: 129730936832.0000 - val_loss: 211586128281.6000 - val_mae: 254631.3125 - val_mse: 197998592000.0000\n",
            "Epoch 295/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127022025787.3723 - mae: 236506.1719 - mse: 126872182784.0000 - val_loss: 210478477585.0667 - val_mae: 252295.0000 - val_mse: 196436066304.0000\n",
            "Epoch 296/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126587427867.5681 - mae: 236249.4062 - mse: 127070683136.0000 - val_loss: 212130174293.3333 - val_mae: 250057.6719 - val_mse: 198043516928.0000\n",
            "Epoch 297/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 127595090596.3425 - mae: 237525.2812 - mse: 127734374400.0000 - val_loss: 210902357879.4667 - val_mae: 252949.4688 - val_mse: 197450956800.0000\n",
            "Epoch 298/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 126564340736.5591 - mae: 237364.4375 - mse: 127139684352.0000 - val_loss: 214005407744.0000 - val_mae: 250252.6406 - val_mse: 198590332928.0000\n",
            "Epoch 299/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128740898540.2811 - mae: 239307.9688 - mse: 128827686912.0000 - val_loss: 216916883319.4667 - val_mae: 251868.0781 - val_mse: 201458188288.0000\n",
            "Epoch 300/300\n",
            "57/57 [==============================] - 0s 5ms/step - loss: 128490314537.3782 - mae: 238021.9531 - mse: 127843385344.0000 - val_loss: 211057261499.7333 - val_mae: 254463.0938 - val_mse: 197802835968.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ef777cd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kpKbrdM4Ar8",
        "colab_type": "code",
        "outputId": "207e618a-5b2c-4084-c954-9a6134b20a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 [==============================] - 0s 3ms/step - loss: 131648623047.1111 - mae: 243630.3594 - mse: 132271185920.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[131648623047.11111, 243630.36, 132271190000.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}